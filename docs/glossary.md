# Glossary: Physical AI & Humanoid Robotics

This glossary defines key terms used throughout the Physical AI & Humanoid Robotics book.

## A

**Action** - In robotics, a specific movement or task performed by a robot, often as part of a larger behavior or plan.

**Agent** - An autonomous entity that perceives its environment and takes actions to achieve goals, commonly used in AI and robotics contexts.

**Artificial Intelligence (AI)** - The simulation of human intelligence processes by machines, especially computer systems, including learning, reasoning, and self-correction.

## B

**Behavior Tree** - A hierarchical tree structure that controls the execution flow of tasks in robotics and AI applications, commonly used for complex decision-making.

## C

**Computer Vision** - A field of artificial intelligence that trains computers to interpret and understand the visual world, using digital images and machine learning models.

**Control System** - A system that manages, commands, directs, or regulates the behavior of other devices or systems, fundamental in robotics for motor control.

## D

**Deep Learning** - A subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns in data.

**Digital Twin** - A virtual representation of a physical object or system that can be used for simulation, analysis, and optimization purposes.

**Distributed Data Service (DDS)** - A middleware protocol and API standard for real-time, scalable, and reliable data exchange between applications, core to ROS 2 architecture.

## E

**Embodied AI** - Artificial intelligence systems that interact with the physical world through robotic bodies, combining perception, reasoning, and action.

## F

**Forward Kinematics** - The use of joint parameters to compute the position and orientation of the end-effector of a robotic arm.

## G

**Gazebo** - A 3D simulation environment for robotics that provides physics simulation and realistic sensor feedback, commonly used with ROS.

## H

**Humanoid Robot** - A robot with a body structure that mimics the human body, typically having a head, torso, two arms, and two legs.

## I

**Inertial Measurement Unit (IMU)** - An electronic device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body.

**Inverse Kinematics** - The mathematical process of calculating joint parameters needed to position the end-effector of a robotic arm at a desired location.

**Isaac Sim** - NVIDIA's robotics simulation application and synthetic data generation tool for developing and testing AI-based robotics applications.

**Isaac ROS** - NVIDIA's collection of hardware-accelerated perception and navigation packages designed for ROS 2.

## K

**Kinematics** - The branch of mechanics concerned with the motion of objects without reference to the forces that cause the motion.

## L

**LiDAR** - Light Detection and Ranging, a remote sensing method that uses light in the form of a pulsed laser to measure distances and create 3D maps of the environment.

**Long Short-Term Memory (LSTM)** - A type of recurrent neural network (RNN) architecture that can learn and remember information over long periods, useful in robotics for sequence prediction.

## M

**Manipulation** - The ability of a robot to physically interact with objects in its environment, typically using end-effectors like grippers or tools.

**Middleware** - Software that provides common services and capabilities to applications beyond what's offered by the operating system, essential in distributed robotics systems like ROS.

## N

**Navigation** - The ability of a robot to move through its environment from one location to another, typically involving path planning, obstacle avoidance, and localization.

**Nav2** - The ROS 2 Navigation Stack, a collection of packages for mobile robot navigation including path planning, obstacle avoidance, and localization.

## O

**OpenAI API** - A set of interfaces provided by OpenAI for accessing their artificial intelligence models, including GPT and Whisper.

**OpenCV** - Open Source Computer Vision Library, an open-source computer vision and machine learning software library.

**Omniverse** - NVIDIA's simulation and collaboration platform based on Pixar's Universal Scene Description (USD) and NVIDIA RTX technology.

## P

**Perception** - The ability of a robot to interpret sensory information from its environment, including vision, touch, and other modalities.

**Point Cloud** - A collection of data points in a three-dimensional coordinate system, typically representing the external surface of an object or environment as captured by 3D scanners or LiDAR.

**Python** - A high-level programming language widely used in robotics and AI development due to its simplicity and extensive libraries.

## Q

**Qdrant** - An open-source vector similarity search engine with extended filtering support, used for semantic search in RAG systems.

## R

**Robot Operating System (ROS)** - A flexible framework for writing robot software that provides a collection of tools, libraries, and conventions for creating robot applications.

**ROS 2** - The second generation of the Robot Operating System, designed for production environments with improved security, real-time support, and multi-robot systems.

**ROS Bridge** - A collection of packages that enable communication between ROS/ROS 2 and other systems, such as web browsers or simulation environments.

**rclpy** - The Python client library for ROS 2, providing Python APIs for ROS concepts like nodes, publishers, subscribers, services, etc.

## S

**Simulation** - The process of creating a virtual model of a real-world system to study its behavior under various conditions, crucial in robotics development.

**SLAM (Simultaneous Localization and Mapping)** - The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**State Estimation** - The process of determining the state of a dynamic system from noisy and incomplete measurements, fundamental in robotics for localization and control.

## T

**Topic** - In ROS/ROS 2, a named bus over which nodes exchange messages, implementing a publish-subscribe communication pattern.

**Transformer** - A type of deep learning model architecture that uses self-attention mechanisms, foundational to many modern LLMs including GPT models.

## U

**Unified Robot Description Format (URDF)** - An XML format for representing a robot model in ROS, describing the robot's physical and kinematic properties.

**Unity** - A cross-platform game engine widely used for creating 3D simulations, including robotics applications with the Unity Robotics package.

## V

**Vision-Language-Action (VLA)** - A paradigm combining visual perception, natural language understanding, and robotic action in a unified system.

**VSLAM (Visual Simultaneous Localization and Mapping)** - A variant of SLAM that uses visual sensors (cameras) to create maps and localize a robot within its environment.

## W

**Whisper** - OpenAI's automatic speech recognition (ASR) system that can transcribe speech to text in multiple languages.

## X, Y, Z

**YAML (YAML Ain't Markup Language)** - A human-readable data serialization language commonly used for configuration files in ROS and other robotics frameworks.

**Zero-Shot Learning** - A machine learning paradigm where a model performs tasks it hasn't been explicitly trained on, using its general understanding of concepts.